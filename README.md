# ğŸ§  Memora â€” Your Private, Memory-Aware AI Agent

> **Runs 100% on your machine. Remembers what matters. Never lies.** Â 
> Built for ethical hackers, AI researchers, and privacy-first users.

[![Streamlit](https://static.streamlit.io/badge/streamlit.svg)](https://streamlit.io) Â 
[![Ollama](https://img.shields.io/badge/Ollama-Supported-orange)](https://ollama.com) Â 
[![Privacy](https://img.shields.io/badge/Privacy-Local_Only-green)](https://github.com/NarlaRohan050/AI-Agent)

---

## ğŸš€ Overview

**Memora** is a **hybrid GPU/CPU AI agent** that combines **Mistral** and **Mistral-Instruct** to deliver truthful, memory-aware reasoningâ€”**completely offline** with **zero data sent to the cloud**.

It is designed for developers and researchers who want full **privacy, control, and transparency** in AI systems.

---

## âœ¨ Features

* âœ… **Persistent memory** using ChromaDB + sentence embeddings Â 
* âœ… **Fact extraction** (name, interests, goals) â€” never invented Â 
* âœ… **Hallucination prevention** â€” refuses to answer unknowns Â 
* âœ… **Dynamic GPU/CPU load balancing** â€” prevents VRAM crashes Â 
* âœ… **Secure memory deletion** â€” `/forget salary` removes all traces Â 
* âœ… **Name conflict resolution** â€” prompts for confirmation Â 
* âœ… **Redundancy blocking** â€” avoids duplicate memories Â 
* âœ… **Privacy-first** â€” no telemetry, no cloud

---

## âš ï¸ Important Notice

Do **NOT** run this project inside cloud-synced folders such as:

* OneDrive Â 
* Dropbox Â 
* Google Drive Â 

âœ… Move the project to a local directory like: `C:\AI-Agent`

---

## ğŸ› ï¸ Requirements

* Python **3.10 or higher** Â 
* **Ollama** installed Â 
* GPU recommended (CPU fallback supported) Â 
* Windows / Linux / macOS Â 

---

## ğŸ“¦ Installation & Setup (Local Only)

### 1ï¸âƒ£ Install Ollama

Download and install Ollama:

```bash
[https://ollama.com/download/OllamaSetup.exe](https://ollama.com/download/OllamaSetup.exe)
````

> Restart your terminal after installation.

-----

### 2ï¸âƒ£ Pull the Quantized Mistral Model

```bash
ollama pull mistral:7b-instruct-v0.2-q5_K_M
```

-----

### 3ï¸âƒ£ Clone the Repository

```bash
git clone [https://github.com/NarlaRohan050/AI-Agent.git](https://github.com/NarlaRohan050/AI-Agent.git)
cd AI-Agent
```

-----

### 4ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

-----

### 5ï¸âƒ£ Run the Application

```bash
streamlit run ui/streamlit_app.py
```

> Open the local URL shown in the terminal.

-----

### 6ï¸âƒ£ Optional: Run Capacity Test

```bash
python test_agent_max_capacity.py
```

-----

## ğŸ” Privacy Guarantee

  * âŒ No cloud APIs Â 
  * âŒ No telemetry Â 
  * âŒ No background uploads Â 
  * âœ… All data stays **on your machine**

-----

## ğŸ“ Project Structure

```yaml
AI-Agent/
â”‚â”€â”€ src/ # Core agent logic
â”‚â”€â”€ ui/ # Streamlit UI
â”‚â”€â”€ models/ # Local models
â”‚â”€â”€ data/ # Persistent memory
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ test_agent_max_capacity.py
â”‚â”€â”€ README.md
```

-----

## ğŸ“„ License

This project is intended for **educational and research purposes**. Â 
Refer to the repository for detailed license information.

-----

âœ… Built with **privacy, control, and transparency**.

```

Now that your `README.md` is complete, do you need help with any other Git commands or steps for your project?
```
