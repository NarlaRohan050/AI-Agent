# src/main.py
from local_reasoner import LocalMemoryAgent
import torch

if __name__ == "__main__":
    device = "cuda" if torch.cuda.is_available() else "cpu"
    agent = LocalMemoryAgent(device=device)
    print("\nğŸ§  Local Reasoning Agent with Contextual Memory Ready!\n")

    while True:
        query = input("ğŸ” Ask me something (or type 'exit'): ").strip()
        if not query:
            continue
        if query.lower() in ("exit", "quit"):
            print("ğŸ‘‹ Goodbye! Memory saved.")
            break

        result = agent.query_with_context(query)

        print("\nğŸ’¬ AI Agent Answer:")
        print(result.get("answer", "âš ï¸ No answer generated."))

        if result.get("context"):
            print("\nğŸ“š Retrieved Contexts:")
            for c in result["context"]:
                print(f"- {c}")
        else:
            print("\nğŸ“š No related memory found yet.")
        print("\n" + "-" * 80 + "\n")
